{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Dueling Deep Q Learning with Doom (+ double DQNs and Prioritized Experience Replay).ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYulVstwzoPZ",
        "colab_type": "text"
      },
      "source": [
        "# DDDQN  (Double Dueling Deep Q Learning with Prioritized Experience Replay)  DoomüïπÔ∏è\n",
        "In this notebook we'll implement an agent <b>that plays Doom by using a Dueling Double Deep Q learning architecture with Prioritized Experience Replay.</b> <br>\n",
        "\n",
        "Our agent playing Doom after 3 hours of training of **CPU**, remember that our agent needs about 2 days of **GPU** to have optimal score, we'll train from beginning to end the most important architectures (PPO with transfer):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/simoninithomas/Deep_reinforcement_learning_Course/master/docs/assets/img/projects/doomdeathmatc.gif\" alt=\"Doom Deathmatch\"/>\n",
        "\n",
        "But we can see that our agent **understand that he needs to kill enemies before being able to move forward (if he moves forward without killing ennemies he will be killed before getting the vest)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDDBHa97zoPe",
        "colab_type": "text"
      },
      "source": [
        "# This is a notebook from [Deep Reinforcement Learning Course with Tensorflow](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)\n",
        "<img src=\"https://raw.githubusercontent.com/simoninithomas/Deep_reinforcement_learning_Course/master/docs/assets/img/DRLC%20Environments.png\" alt=\"Deep Reinforcement Course\"/>\n",
        "<br>\n",
        "<p>  Deep Reinforcement Learning Course is a free series of articles and videos tutorials üÜï about Deep Reinforcement Learning, where **we'll learn the main algorithms (Q-learning, Deep Q Nets, Dueling Deep Q Nets, Policy Gradients, A2C, Proximal Policy Gradients‚Ä¶), and how to implement them with Tensorflow.**\n",
        "<br><br>\n",
        "    \n",
        "üìúThe articles explain the architectures from the big picture to the mathematical details behind them.\n",
        "<br>\n",
        "üìπ The videos explain how to build the agents with Tensorflow </b></p>\n",
        "<br>\n",
        "This course will give you a **solid foundation for understanding and implementing the future state of the art algorithms**. And, you'll build a strong professional portfolio by creating **agents that learn to play awesome environments**: Doom¬© üëπ, Space invaders üëæ, Outrun, Sonic the Hedgehog¬©, Michael Jackson‚Äôs Moonwalker, agents that will be able to navigate in 3D environments with DeepMindLab (Quake) and able to walk with Mujoco. \n",
        "<br><br>\n",
        "</p> \n",
        "\n",
        "## üìö The complete [Syllabus HERE](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)\n",
        "\n",
        "\n",
        "## Any questions üë®‚Äçüíª\n",
        "<p> If you have any questions, feel free to ask me: </p>\n",
        "<p> üìß: <a href=\"mailto:hello@simoninithomas.com\">hello@simoninithomas.com</a>  </p>\n",
        "<p> Github: https://github.com/simoninithomas/Deep_reinforcement_learning_Course </p>\n",
        "<p> üåê : https://simoninithomas.github.io/Deep_reinforcement_learning_Course/ </p>\n",
        "<p> Twitter: <a href=\"https://twitter.com/ThomasSimonini\">@ThomasSimonini</a> </p>\n",
        "<p> Don't forget to <b> follow me on <a href=\"https://twitter.com/ThomasSimonini\">twitter</a>, <a href=\"https://github.com/simoninithomas/Deep_reinforcement_learning_Course\">github</a> and <a href=\"https://medium.com/@thomassimonini\">Medium</a> to be alerted of the new articles that I publish </b></p>\n",
        "    \n",
        "## How to help  üôå\n",
        "3 ways:\n",
        "- **Clap our articles and like our videos a lot**:Clapping in Medium means that you really like our articles. And the more claps we have, the more our article is shared Liking our videos help them to be much more visible to the deep learning community.\n",
        "- **Share and speak about our articles and videos**: By sharing our articles and videos you help us to spread the word. \n",
        "- **Improve our notebooks**: if you found a bug or **a better implementation** you can send a pull request.\n",
        "<br>\n",
        "\n",
        "## Important note ü§î\n",
        "<b> You can run it on your computer but it's better to run it on GPU based services</b>, personally I use Microsoft Azure and their Deep Learning Virtual Machine (they offer 170$)\n",
        "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft-ads.dsvm-deep-learning\n",
        "<br>\n",
        "‚ö†Ô∏è I don't have any business relations with them. I just loved their excellent customer service.\n",
        "\n",
        "If you have some troubles to use Microsoft Azure follow the explainations of this excellent article here (without last the part fast.ai): https://medium.com/@manikantayadunanda/setting-up-deeplearning-machine-and-fast-ai-on-azure-a22eb6bd6429"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0NKfF8rzoPg",
        "colab_type": "text"
      },
      "source": [
        "## Prerequisites üèóÔ∏è\n",
        "Before diving on the notebook **you need to understand**:\n",
        "- The foundations of Reinforcement learning (MC, TD, Rewards hypothesis...) [Article](https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419)\n",
        "- Q-learning [Article](https://medium.freecodecamp.org/diving-deeper-into-reinforcement-learning-with-q-learning-c18d0db58efe)\n",
        "- Deep Q-Learning [Article](https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8)\n",
        "- Improvments in Deep Q-learning [Article]()\n",
        "- You can follow this notebook using my [video tutorial](https://www.youtube.com/embed/-Ynjw0Vl3i4?showinfo=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHCw9ZS5zoPk",
        "colab_type": "code",
        "outputId": "7ebea222-9460-4df1-9aaa-74415598d506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "from IPython.display import HTML\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/-Ynjw0Vl3i4?showinfo=0\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/-Ynjw0Vl3i4?showinfo=0\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SdvkupazoPv",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Import the libraries üìö"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlxwpgSv1mRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6643bf4e-c753-459f-da0d-d2b79e37884d"
      },
      "source": [
        "%%bash\n",
        "# Install deps from \n",
        "# https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md#-linux\n",
        "\n",
        "apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n",
        "nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n",
        "libopenal-dev timidity libwildmidi-dev unzip\n",
        "\n",
        "# Boost libraries\n",
        "apt-get install libboost-all-dev\n",
        "\n",
        "# Lua binding dependencies\n",
        "apt-get install liblua5.1-dev"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu8).\n",
            "libjpeg-dev set to manually installed.\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
            "zlib1g-dev set to manually installed.\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.1).\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.5).\n",
            "libbz2-dev is already the newest version (1.0.6-8.1ubuntu0.2).\n",
            "libbz2-dev set to manually installed.\n",
            "tar is already the newest version (1.29b-2ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  autoconf automake autopoint autotools-dev debhelper dh-autoreconf\n",
            "  dh-strip-nondeterminism file freepats gettext gettext-base gir1.2-atk-1.0\n",
            "  gir1.2-freedesktop gir1.2-gdkpixbuf-2.0 gir1.2-gtk-2.0 gir1.2-ibus-1.0\n",
            "  gir1.2-pango-1.0 intltool-debian libarchive-cpio-perl libarchive-zip-perl\n",
            "  libatk1.0-dev libaudio2 libcairo-script-interpreter2 libcairo2-dev\n",
            "  libcapnp-0.6.1 libdbus-1-dev libfile-stripnondeterminism-perl libfluidsynth1\n",
            "  libgdk-pixbuf2.0-dev libibus-1.0-5 libibus-1.0-dev libmagic-mgc libmagic1\n",
            "  libmail-sendmail-perl libmirclient-dev libmirclient9 libmircommon-dev\n",
            "  libmircommon7 libmircookie-dev libmircookie2 libmircore-dev libmircore1\n",
            "  libmirprotobuf3 libpango1.0-dev libpangoxft-1.0-0 libpixman-1-dev\n",
            "  libprotobuf-dev libprotobuf-lite10 libpulse-dev libpulse-mainloop-glib0\n",
            "  libsigsegv2 libsndio-dev libsys-hostname-long-perl libtimedate-perl libtool\n",
            "  libudev-dev libwildmidi-config libwildmidi2 libxcb-shm0-dev\n",
            "  libxcomposite-dev libxcursor-dev libxinerama-dev libxkbcommon-dev\n",
            "  libxml2-utils libxrandr-dev libxv-dev m4 po-debconf timidity-daemon\n",
            "  x11proto-composite-dev x11proto-randr-dev x11proto-xinerama-dev\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc dh-make dwz gettext-doc\n",
            "  libasprintf-dev libgettextpo-dev nas libcairo2-doc fluidr3mono-gm-soundfont\n",
            "  | timgm6mb-soundfont | fluid-soundfont-gm libgtk2.0-doc imagemagick\n",
            "  libpango1.0-doc libtool-doc gcj-jdk m4-doc libmail-box-perl\n",
            "  fluid-soundfont-gm fluid-soundfont-gs pmidi\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autopoint autotools-dev debhelper dh-autoreconf\n",
            "  dh-strip-nondeterminism file freepats gettext gettext-base gir1.2-atk-1.0\n",
            "  gir1.2-freedesktop gir1.2-gdkpixbuf-2.0 gir1.2-gtk-2.0 gir1.2-ibus-1.0\n",
            "  gir1.2-pango-1.0 intltool-debian libarchive-cpio-perl libarchive-zip-perl\n",
            "  libatk1.0-dev libaudio2 libcairo-script-interpreter2 libcairo2-dev\n",
            "  libcapnp-0.6.1 libdbus-1-dev libfile-stripnondeterminism-perl\n",
            "  libfluidsynth-dev libfluidsynth1 libgdk-pixbuf2.0-dev libgme-dev\n",
            "  libgtk2.0-dev libibus-1.0-5 libibus-1.0-dev libmagic-mgc libmagic1\n",
            "  libmail-sendmail-perl libmirclient-dev libmirclient9 libmircommon-dev\n",
            "  libmircommon7 libmircookie-dev libmircookie2 libmircore-dev libmircore1\n",
            "  libmirprotobuf3 libopenal-dev libpango1.0-dev libpangoxft-1.0-0\n",
            "  libpixman-1-dev libprotobuf-dev libprotobuf-lite10 libpulse-dev\n",
            "  libpulse-mainloop-glib0 libsdl2-dev libsigsegv2 libsndio-dev\n",
            "  libsys-hostname-long-perl libtimedate-perl libtool libudev-dev\n",
            "  libwildmidi-config libwildmidi-dev libwildmidi2 libxcb-shm0-dev\n",
            "  libxcomposite-dev libxcursor-dev libxinerama-dev libxkbcommon-dev\n",
            "  libxml2-utils libxrandr-dev libxv-dev m4 nasm po-debconf timidity\n",
            "  timidity-daemon x11proto-composite-dev x11proto-randr-dev\n",
            "  x11proto-xinerama-dev\n",
            "0 upgraded, 80 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 43.2 MB of archives.\n",
            "After this operation, 114 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.3 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.3 [68.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.3 [22.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext-base amd64 0.19.8.1-6ubuntu0.3 [113 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 autopoint all 0.19.8.1-6ubuntu0.3 [426 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtool all 2.4.6-2 [194 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-autoreconf all 17 [15.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libarchive-zip-perl all 1.60-1ubuntu0.1 [84.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfile-stripnondeterminism-perl all 0.040-1.1~build1 [13.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-strip-nondeterminism all 0.040-1.1~build1 [5,208 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext amd64 0.19.8.1-6ubuntu0.3 [1,293 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 intltool-debian all 0.35.0+20060710.4 [24.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 po-debconf all 1.0.20 [232 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 debhelper all 11.1.6ubuntu2 [902 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 freepats all 20060219-1 [29.0 MB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-atk-1.0 amd64 2.28.1-1 [17.8 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-freedesktop amd64 1.56.1-1 [9,080 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-gdkpixbuf-2.0 amd64 2.36.11-2 [7,748 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoxft-1.0-0 amd64 1.40.14-1ubuntu0.1 [15.0 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gir1.2-pango-1.0 amd64 1.40.14-1ubuntu0.1 [21.6 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-gtk-2.0 amd64 2.24.32-1ubuntu1 [172 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibus-1.0-5 amd64 1.5.17-3ubuntu5.2 [134 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gir1.2-ibus-1.0 amd64 1.5.17-3ubuntu5.2 [66.5 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libarchive-cpio-perl all 0.10-1 [9,644 B]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk1.0-dev amd64 2.28.1-1 [79.9 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libaudio2 amd64 1.9.4-6 [50.3 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo-script-interpreter2 amd64 1.15.10-2ubuntu0.1 [53.5 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-dev amd64 0.34.0-2 [244 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0-dev amd64 1.13-2~ubuntu18.04 [6,684 B]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2-dev amd64 1.15.10-2ubuntu0.1 [626 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcapnp-0.6.1 amd64 0.6.1-1ubuntu1 [658 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdbus-1-dev amd64 1.12.2-1ubuntu1.1 [165 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfluidsynth1 amd64 1.1.9-1 [137 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfluidsynth-dev amd64 1.1.9-1 [19.7 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-dev amd64 2.36.11-2 [46.8 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgme-dev amd64 0.6.2-1 [5,796 B]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango1.0-dev amd64 1.40.14-1ubuntu0.1 [288 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xinerama-dev all 2018.4-4 [2,628 B]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama-dev amd64 2:1.1.3-1 [8,404 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-randr-dev all 2018.4-4 [2,620 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr-dev amd64 2:1.5.1-1 [24.0 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor-dev amd64 1:1.1.15-1 [26.5 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-composite-dev all 1:2018.4-4 [2,620 B]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcomposite-dev amd64 1:0.4.4-2 [9,136 B]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxml2-utils amd64 2.9.4+dfsg1-6.1ubuntu1.2 [35.8 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-dev amd64 2.24.32-1ubuntu1 [2,652 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibus-1.0-dev amd64 1.5.17-3ubuntu5.2 [145 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsys-hostname-long-perl all 1.5-1 [11.7 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmail-sendmail-perl all 0.80-1 [22.6 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore1 amd64 0.31.1-0ubuntu1 [26.5 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon7 amd64 0.31.1-0ubuntu1 [73.9 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-lite10 amd64 3.0.0-9.1ubuntu1 [97.7 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirprotobuf3 amd64 0.31.1-0ubuntu1 [127 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient9 amd64 0.31.1-0ubuntu1 [199 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore-dev amd64 0.31.1-0ubuntu1 [21.7 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-dev amd64 3.0.0-9.1ubuntu1 [959 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxkbcommon-dev amd64 0.8.2-1~ubuntu18.04.1 [150 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon-dev amd64 0.31.1-0ubuntu1 [13.9 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie2 amd64 0.31.1-0ubuntu1 [19.7 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie-dev amd64 0.31.1-0ubuntu1 [4,392 B]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient-dev amd64 0.31.1-0ubuntu1 [47.8 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenal-dev amd64 1:1.18.2-2 [20.9 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-mainloop-glib0 amd64 1:11.1-1ubuntu7.4 [22.1 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-dev amd64 1:11.1-1ubuntu7.4 [81.5 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsndio-dev amd64 1.1.0-3 [13.3 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libudev-dev amd64 237-3ubuntu10.33 [19.1 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxv-dev amd64 2:1.0.11-1 [32.5 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsdl2-dev amd64 2.0.8+dfsg1-1ubuntu1.18.04.4 [683 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libwildmidi-config all 0.4.2-1 [7,212 B]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libwildmidi2 amd64 0.4.2-1 [55.8 kB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libwildmidi-dev amd64 0.4.2-1 [86.4 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu bionic/universe amd64 nasm amd64 2.13.02-0.1 [359 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu bionic/universe amd64 timidity amd64 2.13.2-41 [585 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu bionic/universe amd64 timidity-daemon all 2.13.2-41 [5,984 B]\n",
            "Fetched 43.2 MB in 6s (7,791 kB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 135004 files and directories currently installed.)\r\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.3_amd64.deb ...\r\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.3) ...\r\n",
            "Selecting previously unselected package libmagic1:amd64.\r\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.3_amd64.deb ...\r\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\r\n",
            "Selecting previously unselected package file.\r\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.3_amd64.deb ...\r\n",
            "Unpacking file (1:5.32-2ubuntu0.3) ...\r\n",
            "Selecting previously unselected package gettext-base.\r\n",
            "Preparing to unpack .../03-gettext-base_0.19.8.1-6ubuntu0.3_amd64.deb ...\r\n",
            "Unpacking gettext-base (0.19.8.1-6ubuntu0.3) ...\r\n",
            "Selecting previously unselected package libsigsegv2:amd64.\r\n",
            "Preparing to unpack .../04-libsigsegv2_2.12-1_amd64.deb ...\r\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\r\n",
            "Selecting previously unselected package m4.\r\n",
            "Preparing to unpack .../05-m4_1.4.18-1_amd64.deb ...\r\n",
            "Unpacking m4 (1.4.18-1) ...\r\n",
            "Selecting previously unselected package autoconf.\r\n",
            "Preparing to unpack .../06-autoconf_2.69-11_all.deb ...\r\n",
            "Unpacking autoconf (2.69-11) ...\r\n",
            "Selecting previously unselected package autotools-dev.\r\n",
            "Preparing to unpack .../07-autotools-dev_20180224.1_all.deb ...\r\n",
            "Unpacking autotools-dev (20180224.1) ...\r\n",
            "Selecting previously unselected package automake.\r\n",
            "Preparing to unpack .../08-automake_1%3a1.15.1-3ubuntu2_all.deb ...\r\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\r\n",
            "Selecting previously unselected package autopoint.\r\n",
            "Preparing to unpack .../09-autopoint_0.19.8.1-6ubuntu0.3_all.deb ...\r\n",
            "Unpacking autopoint (0.19.8.1-6ubuntu0.3) ...\r\n",
            "Selecting previously unselected package libtool.\r\n",
            "Preparing to unpack .../10-libtool_2.4.6-2_all.deb ...\r\n",
            "Unpacking libtool (2.4.6-2) ...\r\n",
            "Selecting previously unselected package dh-autoreconf.\r\n",
            "Preparing to unpack .../11-dh-autoreconf_17_all.deb ...\r\n",
            "Unpacking dh-autoreconf (17) ...\r\n",
            "Selecting previously unselected package libarchive-zip-perl.\r\n",
            "Preparing to unpack .../12-libarchive-zip-perl_1.60-1ubuntu0.1_all.deb ...\r\n",
            "Unpacking libarchive-zip-perl (1.60-1ubuntu0.1) ...\r\n",
            "Selecting previously unselected package libfile-stripnondeterminism-perl.\r\n",
            "Preparing to unpack .../13-libfile-stripnondeterminism-perl_0.040-1.1~build1_all.deb ...\r\n",
            "Unpacking libfile-stripnondeterminism-perl (0.040-1.1~build1) ...\r\n",
            "Selecting previously unselected package libtimedate-perl.\r\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\r\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\r\n",
            "Selecting previously unselected package dh-strip-nondeterminism.\r\n",
            "Preparing to unpack .../15-dh-strip-nondeterminism_0.040-1.1~build1_all.deb ...\r\n",
            "Unpacking dh-strip-nondeterminism (0.040-1.1~build1) ...\r\n",
            "Selecting previously unselected package gettext.\r\n",
            "Preparing to unpack .../16-gettext_0.19.8.1-6ubuntu0.3_amd64.deb ...\r\n",
            "Unpacking gettext (0.19.8.1-6ubuntu0.3) ...\r\n",
            "Selecting previously unselected package intltool-debian.\r\n",
            "Preparing to unpack .../17-intltool-debian_0.35.0+20060710.4_all.deb ...\r\n",
            "Unpacking intltool-debian (0.35.0+20060710.4) ...\r\n",
            "Selecting previously unselected package po-debconf.\r\n",
            "Preparing to unpack .../18-po-debconf_1.0.20_all.deb ...\r\n",
            "Unpacking po-debconf (1.0.20) ...\r\n",
            "Selecting previously unselected package debhelper.\r\n",
            "Preparing to unpack .../19-debhelper_11.1.6ubuntu2_all.deb ...\r\n",
            "Unpacking debhelper (11.1.6ubuntu2) ...\r\n",
            "Selecting previously unselected package freepats.\r\n",
            "Preparing to unpack .../20-freepats_20060219-1_all.deb ...\r\n",
            "Unpacking freepats (20060219-1) ...\r\n",
            "Selecting previously unselected package gir1.2-atk-1.0:amd64.\r\n",
            "Preparing to unpack .../21-gir1.2-atk-1.0_2.28.1-1_amd64.deb ...\r\n",
            "Unpacking gir1.2-atk-1.0:amd64 (2.28.1-1) ...\r\n",
            "Selecting previously unselected package gir1.2-freedesktop:amd64.\r\n",
            "Preparing to unpack .../22-gir1.2-freedesktop_1.56.1-1_amd64.deb ...\r\n",
            "Unpacking gir1.2-freedesktop:amd64 (1.56.1-1) ...\r\n",
            "Selecting previously unselected package gir1.2-gdkpixbuf-2.0:amd64.\r\n",
            "Preparing to unpack .../23-gir1.2-gdkpixbuf-2.0_2.36.11-2_amd64.deb ...\r\n",
            "Unpacking gir1.2-gdkpixbuf-2.0:amd64 (2.36.11-2) ...\r\n",
            "Selecting previously unselected package libpangoxft-1.0-0:amd64.\r\n",
            "Preparing to unpack .../24-libpangoxft-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\r\n",
            "Unpacking libpangoxft-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\r\n",
            "Selecting previously unselected package gir1.2-pango-1.0:amd64.\r\n",
            "Preparing to unpack .../25-gir1.2-pango-1.0_1.40.14-1ubuntu0.1_amd64.deb ...\r\n",
            "Unpacking gir1.2-pango-1.0:amd64 (1.40.14-1ubuntu0.1) ...\r\n",
            "Selecting previously unselected package gir1.2-gtk-2.0.\r\n",
            "Preparing to unpack .../26-gir1.2-gtk-2.0_2.24.32-1ubuntu1_amd64.deb ...\r\n",
            "Unpacking gir1.2-gtk-2.0 (2.24.32-1ubuntu1) ...\r\n",
            "Selecting previously unselected package libibus-1.0-5:amd64.\r\n",
            "Preparing to unpack .../27-libibus-1.0-5_1.5.17-3ubuntu5.2_amd64.deb ...\r\n",
            "Unpacking libibus-1.0-5:amd64 (1.5.17-3ubuntu5.2) ...\r\n",
            "Selecting previously unselected package gir1.2-ibus-1.0:amd64.\r\n",
            "Preparing to unpack .../28-gir1.2-ibus-1.0_1.5.17-3ubuntu5.2_amd64.deb ...\r\n",
            "Unpacking gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu5.2) ...\r\n",
            "Selecting previously unselected package libarchive-cpio-perl.\r\n",
            "Preparing to unpack .../29-libarchive-cpio-perl_0.10-1_all.deb ...\r\n",
            "Unpacking libarchive-cpio-perl (0.10-1) ...\r\n",
            "Selecting previously unselected package libatk1.0-dev:amd64.\r\n",
            "Preparing to unpack .../30-libatk1.0-dev_2.28.1-1_amd64.deb ...\r\n",
            "Unpacking libatk1.0-dev:amd64 (2.28.1-1) ...\r\n",
            "Selecting previously unselected package libaudio2:amd64.\r\n",
            "Preparing to unpack .../31-libaudio2_1.9.4-6_amd64.deb ...\r\n",
            "Unpacking libaudio2:amd64 (1.9.4-6) ...\r\n",
            "Selecting previously unselected package libcairo-script-interpreter2:amd64.\r\n",
            "Preparing to unpack .../32-libcairo-script-interpreter2_1.15.10-2ubuntu0.1_amd64.deb ...\r\n",
            "Unpacking libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\r\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\r\n",
            "Preparing to unpack .../33-libpixman-1-dev_0.34.0-2_amd64.deb ...\r\n",
            "Unpacking libpixman-1-dev:amd64 (0.34.0-2) ...\r\n",
            "Selecting previously unselected package libxcb-shm0-dev:amd64.\r\n",
            "Preparing to unpack .../34-libxcb-shm0-dev_1.13-2~ubuntu18.04_amd64.deb ...\r\n",
            "Unpacking libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\r\n",
            "Selecting previously unselected package libcairo2-dev:amd64.\r\n",
            "Preparing to unpack .../35-libcairo2-dev_1.15.10-2ubuntu0.1_amd64.deb ...\r\n",
            "Unpacking libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\r\n",
            "Selecting previously unselected package libcapnp-0.6.1:amd64.\r\n",
            "Preparing to unpack .../36-libcapnp-0.6.1_0.6.1-1ubuntu1_amd64.deb ...\r\n",
            "Unpacking libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\r\n",
            "Selecting previously unselected package libdbus-1-dev:amd64.\r\n",
            "Preparing to unpack .../37-libdbus-1-dev_1.12.2-1ubuntu1.1_amd64.deb ...\r\n",
            "Unpacking libdbus-1-dev:amd64 (1.12.2-1ubuntu1.1) ...\r\n",
            "Selecting previously unselected package libfluidsynth1:amd64.\r\n",
            "Preparing to unpack .../38-libfluidsynth1_1.1.9-1_amd64.deb ...\r\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\r\n",
            "Selecting previously unselected package libfluidsynth-dev:amd64.\r\n",
            "Preparing to unpack .../39-libfluidsynth-dev_1.1.9-1_amd64.deb ...\r\n",
            "Unpacking libfluidsynth-dev:amd64 (1.1.9-1) ...\r\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-dev.\r\n",
            "Preparing to unpack .../40-libgdk-pixbuf2.0-dev_2.36.11-2_amd64.deb ...\r\n",
            "Unpacking libgdk-pixbuf2.0-dev (2.36.11-2) ...\r\n",
            "Selecting previously unselected package libgme-dev:amd64.\r\n",
            "Preparing to unpack .../41-libgme-dev_0.6.2-1_amd64.deb ...\r\n",
            "Unpacking libgme-dev:amd64 (0.6.2-1) ...\r\n",
            "Selecting previously unselected package libpango1.0-dev.\r\n",
            "Preparing to unpack .../42-libpango1.0-dev_1.40.14-1ubuntu0.1_amd64.deb ...\r\n",
            "Unpacking libpango1.0-dev (1.40.14-1ubuntu0.1) ...\r\n",
            "Selecting previously unselected package x11proto-xinerama-dev.\r\n",
            "Preparing to unpack .../43-x11proto-xinerama-dev_2018.4-4_all.deb ...\r\n",
            "Unpacking x11proto-xinerama-dev (2018.4-4) ...\r\n",
            "Selecting previously unselected package libxinerama-dev:amd64.\r\n",
            "Preparing to unpack .../44-libxinerama-dev_2%3a1.1.3-1_amd64.deb ...\r\n",
            "Unpacking libxinerama-dev:amd64 (2:1.1.3-1) ...\r\n",
            "Selecting previously unselected package x11proto-randr-dev.\r\n",
            "Preparing to unpack .../45-x11proto-randr-dev_2018.4-4_all.deb ...\r\n",
            "Unpacking x11proto-randr-dev (2018.4-4) ...\r\n",
            "Selecting previously unselected package libxrandr-dev:amd64.\r\n",
            "Preparing to unpack .../46-libxrandr-dev_2%3a1.5.1-1_amd64.deb ...\r\n",
            "Unpacking libxrandr-dev:amd64 (2:1.5.1-1) ...\r\n",
            "Selecting previously unselected package libxcursor-dev:amd64.\r\n",
            "Preparing to unpack .../47-libxcursor-dev_1%3a1.1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcursor-dev:amd64 (1:1.1.15-1) ...\r\n",
            "Selecting previously unselected package x11proto-composite-dev.\r\n",
            "Preparing to unpack .../48-x11proto-composite-dev_1%3a2018.4-4_all.deb ...\r\n",
            "Unpacking x11proto-composite-dev (1:2018.4-4) ...\r\n",
            "Selecting previously unselected package libxcomposite-dev:amd64.\r\n",
            "Preparing to unpack .../49-libxcomposite-dev_1%3a0.4.4-2_amd64.deb ...\r\n",
            "Unpacking libxcomposite-dev:amd64 (1:0.4.4-2) ...\r\n",
            "Selecting previously unselected package libxml2-utils.\r\n",
            "Preparing to unpack .../50-libxml2-utils_2.9.4+dfsg1-6.1ubuntu1.2_amd64.deb ...\r\n",
            "Unpacking libxml2-utils (2.9.4+dfsg1-6.1ubuntu1.2) ...\r\n",
            "Selecting previously unselected package libgtk2.0-dev.\r\n",
            "Preparing to unpack .../51-libgtk2.0-dev_2.24.32-1ubuntu1_amd64.deb ...\r\n",
            "Unpacking libgtk2.0-dev (2.24.32-1ubuntu1) ...\r\n",
            "Selecting previously unselected package libibus-1.0-dev:amd64.\r\n",
            "Preparing to unpack .../52-libibus-1.0-dev_1.5.17-3ubuntu5.2_amd64.deb ...\r\n",
            "Unpacking libibus-1.0-dev:amd64 (1.5.17-3ubuntu5.2) ...\r\n",
            "Selecting previously unselected package libsys-hostname-long-perl.\r\n",
            "Preparing to unpack .../53-libsys-hostname-long-perl_1.5-1_all.deb ...\r\n",
            "Unpacking libsys-hostname-long-perl (1.5-1) ...\r\n",
            "Selecting previously unselected package libmail-sendmail-perl.\r\n",
            "Preparing to unpack .../54-libmail-sendmail-perl_0.80-1_all.deb ...\r\n",
            "Unpacking libmail-sendmail-perl (0.80-1) ...\r\n",
            "Selecting previously unselected package libmircore1:amd64.\r\n",
            "Preparing to unpack .../55-libmircore1_0.31.1-0ubuntu1_amd64.deb ...\r\n",
            "Unpacking libmircore1:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Selecting previously unselected package libmircommon7:amd64.\r\n",
            "Preparing to unpack .../56-libmircommon7_0.31.1-0ubuntu1_amd64.deb ...\r\n",
            "Unpacking libmircommon7:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\r\n",
            "Preparing to unpack .../57-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\r\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\r\n",
            "Selecting previously unselected package libmirprotobuf3:amd64.\r\n",
            "Preparing to unpack .../58-libmirprotobuf3_0.31.1-0ubuntu1_amd64.deb ...\r\n",
            "Unpacking libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Selecting previously unselected package libmirclient9:amd64.\r\n",
            "Preparing to unpack .../59-libmirclient9_0.31.1-0ubuntu1_amd64.deb ...\r\n",
            "Unpacking libmirclient9:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Selecting previously unselected package libmircore-dev:amd64.\r\n",
            "Preparing to unpack .../60-libmircore-dev_0.31.1-0ubuntu1_amd64.deb ...\r\n",
            "Unpacking libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\r\n",
            "Preparing to unpack .../61-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\r\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\r\n",
            "Selecting previously unselected package libxkbcommon-dev:amd64.\r\n",
            "Preparing to unpack .../62-libxkbcommon-dev_0.8.2-1~ubuntu18.04.1_amd64.deb ...\r\n",
            "Unpacking libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\r\n",
            "Selecting previously unselected package libmircommon-dev:amd64.\r\n",
            "Preparing to unpack .../63-libmircommon-dev_0.31.1-0ubuntu1_amd64.deb ...\r\n",
            "Unpacking libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Selecting previously unselected package libmircookie2:amd64.\r\n",
            "Preparing to unpack .../64-libmircookie2_0.31.1-0ubuntu1_amd64.deb ...\r\n",
            "Unpacking libmircookie2:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Selecting previously unselected package libmircookie-dev:amd64.\r\n",
            "Preparing to unpack .../65-libmircookie-dev_0.31.1-0ubuntu1_amd64.deb ...\r\n",
            "Unpacking libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Selecting previously unselected package libmirclient-dev:amd64.\r\n",
            "Preparing to unpack .../66-libmirclient-dev_0.31.1-0ubuntu1_amd64.deb ...\r\n",
            "Unpacking libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Selecting previously unselected package libopenal-dev:amd64.\r\n",
            "Preparing to unpack .../67-libopenal-dev_1%3a1.18.2-2_amd64.deb ...\r\n",
            "Unpacking libopenal-dev:amd64 (1:1.18.2-2) ...\r\n",
            "Selecting previously unselected package libpulse-mainloop-glib0:amd64.\r\n",
            "Preparing to unpack .../68-libpulse-mainloop-glib0_1%3a11.1-1ubuntu7.4_amd64.deb ...\r\n",
            "Unpacking libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.4) ...\r\n",
            "Selecting previously unselected package libpulse-dev:amd64.\r\n",
            "Preparing to unpack .../69-libpulse-dev_1%3a11.1-1ubuntu7.4_amd64.deb ...\r\n",
            "Unpacking libpulse-dev:amd64 (1:11.1-1ubuntu7.4) ...\r\n",
            "Selecting previously unselected package libsndio-dev:amd64.\r\n",
            "Preparing to unpack .../70-libsndio-dev_1.1.0-3_amd64.deb ...\r\n",
            "Unpacking libsndio-dev:amd64 (1.1.0-3) ...\r\n",
            "Selecting previously unselected package libudev-dev:amd64.\r\n",
            "Preparing to unpack .../71-libudev-dev_237-3ubuntu10.33_amd64.deb ...\r\n",
            "Unpacking libudev-dev:amd64 (237-3ubuntu10.33) ...\r\n",
            "Selecting previously unselected package libxv-dev:amd64.\r\n",
            "Preparing to unpack .../72-libxv-dev_2%3a1.0.11-1_amd64.deb ...\r\n",
            "Unpacking libxv-dev:amd64 (2:1.0.11-1) ...\r\n",
            "Selecting previously unselected package libsdl2-dev:amd64.\r\n",
            "Preparing to unpack .../73-libsdl2-dev_2.0.8+dfsg1-1ubuntu1.18.04.4_amd64.deb ...\r\n",
            "Unpacking libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\r\n",
            "Selecting previously unselected package libwildmidi-config.\r\n",
            "Preparing to unpack .../74-libwildmidi-config_0.4.2-1_all.deb ...\r\n",
            "Unpacking libwildmidi-config (0.4.2-1) ...\r\n",
            "Selecting previously unselected package libwildmidi2:amd64.\r\n",
            "Preparing to unpack .../75-libwildmidi2_0.4.2-1_amd64.deb ...\r\n",
            "Unpacking libwildmidi2:amd64 (0.4.2-1) ...\r\n",
            "Selecting previously unselected package libwildmidi-dev.\r\n",
            "Preparing to unpack .../76-libwildmidi-dev_0.4.2-1_amd64.deb ...\r\n",
            "Unpacking libwildmidi-dev (0.4.2-1) ...\r\n",
            "Selecting previously unselected package nasm.\r\n",
            "Preparing to unpack .../77-nasm_2.13.02-0.1_amd64.deb ...\r\n",
            "Unpacking nasm (2.13.02-0.1) ...\r\n",
            "Selecting previously unselected package timidity.\r\n",
            "Preparing to unpack .../78-timidity_2.13.2-41_amd64.deb ...\r\n",
            "Unpacking timidity (2.13.2-41) ...\r\n",
            "Selecting previously unselected package timidity-daemon.\r\n",
            "Preparing to unpack .../79-timidity-daemon_2.13.2-41_all.deb ...\r\n",
            "Unpacking timidity-daemon (2.13.2-41) ...\r\n",
            "Setting up libdbus-1-dev:amd64 (1.12.2-1ubuntu1.1) ...\r\n",
            "Setting up libxcursor-dev:amd64 (1:1.1.15-1) ...\r\n",
            "Setting up gir1.2-atk-1.0:amd64 (2.28.1-1) ...\r\n",
            "Setting up libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\r\n",
            "Setting up libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.4) ...\r\n",
            "Setting up libpulse-dev:amd64 (1:11.1-1ubuntu7.4) ...\r\n",
            "Setting up libarchive-zip-perl (1.60-1ubuntu0.1) ...\r\n",
            "Setting up libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Setting up libtimedate-perl (2.3000-2) ...\r\n",
            "Setting up libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\r\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\r\n",
            "Setting up libgme-dev:amd64 (0.6.2-1) ...\r\n",
            "Setting up gir1.2-freedesktop:amd64 (1.56.1-1) ...\r\n",
            "Setting up libsndio-dev:amd64 (1.1.0-3) ...\r\n",
            "Setting up libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\r\n",
            "Setting up libpangoxft-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\r\n",
            "Setting up libxml2-utils (2.9.4+dfsg1-6.1ubuntu1.2) ...\r\n",
            "Setting up libarchive-cpio-perl (0.10-1) ...\r\n",
            "Setting up gir1.2-gdkpixbuf-2.0:amd64 (2.36.11-2) ...\r\n",
            "Setting up libatk1.0-dev:amd64 (2.28.1-1) ...\r\n",
            "Setting up gettext-base (0.19.8.1-6ubuntu0.3) ...\r\n",
            "Setting up m4 (1.4.18-1) ...\r\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.3) ...\r\n",
            "Setting up gir1.2-pango-1.0:amd64 (1.40.14-1ubuntu0.1) ...\r\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\r\n",
            "Setting up libopenal-dev:amd64 (1:1.18.2-2) ...\r\n",
            "Setting up libsys-hostname-long-perl (1.5-1) ...\r\n",
            "Setting up libwildmidi-config (0.4.2-1) ...\r\n",
            "Setting up libmircookie2:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Setting up libgdk-pixbuf2.0-dev (2.36.11-2) ...\r\n",
            "Setting up libmail-sendmail-perl (0.80-1) ...\r\n",
            "Setting up x11proto-xinerama-dev (2018.4-4) ...\r\n",
            "Setting up autotools-dev (20180224.1) ...\r\n",
            "Setting up libpixman-1-dev:amd64 (0.34.0-2) ...\r\n",
            "Setting up x11proto-randr-dev (2018.4-4) ...\r\n",
            "Setting up libxinerama-dev:amd64 (2:1.1.3-1) ...\r\n",
            "Setting up libxv-dev:amd64 (2:1.0.11-1) ...\r\n",
            "Setting up nasm (2.13.02-0.1) ...\r\n",
            "Setting up libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\r\n",
            "Setting up libibus-1.0-5:amd64 (1.5.17-3ubuntu5.2) ...\r\n",
            "Setting up libmircore1:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Setting up freepats (20060219-1) ...\r\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\r\n",
            "Setting up libudev-dev:amd64 (237-3ubuntu10.33) ...\r\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\r\n",
            "Setting up x11proto-composite-dev (1:2018.4-4) ...\r\n",
            "Setting up autopoint (0.19.8.1-6ubuntu0.3) ...\r\n",
            "Setting up libaudio2:amd64 (1.9.4-6) ...\r\n",
            "Setting up libfile-stripnondeterminism-perl (0.040-1.1~build1) ...\r\n",
            "Setting up gir1.2-gtk-2.0 (2.24.32-1ubuntu1) ...\r\n",
            "Setting up gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu5.2) ...\r\n",
            "Setting up libxrandr-dev:amd64 (2:1.5.1-1) ...\r\n",
            "Setting up libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\r\n",
            "Setting up gettext (0.19.8.1-6ubuntu0.3) ...\r\n",
            "Setting up libxcomposite-dev:amd64 (1:0.4.4-2) ...\r\n",
            "Setting up libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\r\n",
            "Setting up autoconf (2.69-11) ...\r\n",
            "Setting up libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Setting up libwildmidi2:amd64 (0.4.2-1) ...\r\n",
            "Setting up file (1:5.32-2ubuntu0.3) ...\r\n",
            "Setting up intltool-debian (0.35.0+20060710.4) ...\r\n",
            "Setting up libibus-1.0-dev:amd64 (1.5.17-3ubuntu5.2) ...\r\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\r\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\r\n",
            "Setting up libmircommon7:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Setting up libpango1.0-dev (1.40.14-1ubuntu0.1) ...\r\n",
            "Setting up libfluidsynth-dev:amd64 (1.1.9-1) ...\r\n",
            "Setting up timidity (2.13.2-41) ...\r\n",
            "Setting up libtool (2.4.6-2) ...\r\n",
            "Setting up po-debconf (1.0.20) ...\r\n",
            "Setting up libwildmidi-dev (0.4.2-1) ...\r\n",
            "Setting up libgtk2.0-dev (2.24.32-1ubuntu1) ...\r\n",
            "Setting up libmirclient9:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Setting up libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Setting up timidity-daemon (2.13.2-41) ...\r\n",
            "Adding group timidity....done\r\n",
            "Adding system user timidity....done\r\n",
            "Adding user `timidity' to group `audio' ...\r\n",
            "Adding user timidity to group audio\r\n",
            "Done.\r\n",
            "invoke-rc.d: could not determine current runlevel\r\n",
            "invoke-rc.d: policy-rc.d denied execution of stop.\r\n",
            "invoke-rc.d: could not determine current runlevel\r\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\r\n",
            "Setting up libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\r\n",
            "Setting up libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\r\n",
            "Setting up debhelper (11.1.6ubuntu2) ...\r\n",
            "Setting up dh-autoreconf (17) ...\r\n",
            "Setting up dh-strip-nondeterminism (0.040-1.1~build1) ...\r\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\r\n",
            "Processing triggers for systemd (237-3ubuntu10.33) ...\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libboost-all-dev is already the newest version (1.65.1.0ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libtool-bin\n",
            "The following NEW packages will be installed:\n",
            "  liblua5.1-0-dev libtool-bin\n",
            "0 upgraded, 2 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 198 kB of archives.\n",
            "After this operation, 1,188 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liblua5.1-0-dev amd64 5.1.5-8.1build2 [119 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtool-bin amd64 2.4.6-2 [79.5 kB]\n",
            "Fetched 198 kB in 1s (308 kB/s)\n",
            "Selecting previously unselected package liblua5.1-0-dev:amd64.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 138030 files and directories currently installed.)\r\n",
            "Preparing to unpack .../liblua5.1-0-dev_5.1.5-8.1build2_amd64.deb ...\r\n",
            "Unpacking liblua5.1-0-dev:amd64 (5.1.5-8.1build2) ...\r\n",
            "Selecting previously unselected package libtool-bin.\r\n",
            "Preparing to unpack .../libtool-bin_2.4.6-2_amd64.deb ...\r\n",
            "Unpacking libtool-bin (2.4.6-2) ...\r\n",
            "Setting up libtool-bin (2.4.6-2) ...\r\n",
            "Setting up liblua5.1-0-dev:amd64 (5.1.5-8.1build2) ...\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCmLVSzP1Ttz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "d7a9e394-39d7-4bc1-e242-ec653e96f841"
      },
      "source": [
        "!pip install vizdoom"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vizdoom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/6c/23565c09387173423883e7881fce53541ff89b5209ca0904c67e577dd6ac/vizdoom-1.1.7.tar.gz (4.9MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.9MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from vizdoom) (1.17.5)\n",
            "Building wheels for collected packages: vizdoom\n",
            "  Building wheel for vizdoom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vizdoom: filename=vizdoom-1.1.7-cp36-none-any.whl size=14285877 sha256=8e252f4abd52b89d67fd17d8e4bc4a99268d9a9f239d7d8e408c66d176ad35af\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/98/04/d96d2c8edb8d1c008d926716257b407e56fb3ee0c81e51d25e\n",
            "Successfully built vizdoom\n",
            "Installing collected packages: vizdoom\n",
            "Successfully installed vizdoom-1.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhP_7xhgzoPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf      # Deep Learning library\n",
        "import numpy as np           # Handle matrices\n",
        "from vizdoom import *        # Doom Environment\n",
        "\n",
        "import random                # Handling random number generation\n",
        "import time                  # Handling time calculation\n",
        "from skimage import transform# Help us to preprocess the frames\n",
        "\n",
        "from collections import deque# Ordered collection with ends\n",
        "import matplotlib.pyplot as plt # Display graphs\n",
        "\n",
        "import warnings # This ignore all the warning messages that are normally printed during the training because of skiimage\n",
        "warnings.filterwarnings('ignore') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVk3TljjzoP4",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Create our environment üéÆ\n",
        "- Now that we imported the libraries/dependencies, we will create our environment.\n",
        "- Doom environment takes:\n",
        "    - A `configuration file` that **handle all the options** (size of the frame, possible actions...)\n",
        "    - A `scenario file`: that **generates the correct scenario** (in our case basic **but you're invited to try other scenarios**).\n",
        "- Note: We have 7 possible actions: turn left, turn right, move left, move right, shoot (attack)...`[[0,0,0,0,1]...]` so we don't need to do one hot encoding (thanks to <a href=\"https://stackoverflow.com/users/2237916/silgon\">silgon</a> for figuring out). \n",
        "\n",
        "### Our environment\n",
        "<img src=\"https://simoninithomas.github.io/Deep_reinforcement_learning_Course/assets/img/video%20projects/deadlycorridor.png\" style=\"max-width:500px;\" alt=\"Vizdoom deadly corridor\"/>\n",
        "\n",
        "The purpose of this scenario is to teach the agent to navigate towards his fundamental goal (the vest) and make sure he survives at the same time.\n",
        "\n",
        "- Map is a corridor with shooting monsters on both sides (6 monsters in total). \n",
        "- A green vest is placed at the oposite end of the corridor. \n",
        "- **Reward is proportional (negative or positive) to change of the distance between the player and the vest.** \n",
        "- If player ignores monsters on the sides and runs straight for the vest he will be killed somewhere along the way. \n",
        "- To ensure this behavior doom_skill = 5 (config) is needed.\n",
        "\n",
        "<br>\n",
        "REWARDS:\n",
        "\n",
        "- +dX for getting closer to the vest. -dX for getting further from the vest.\n",
        "- death penalty = 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ues9-9ms3cRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c969e5d1-0e67-4068-ec94-4154cf0478a8"
      },
      "source": [
        "!wget https://github.com/mbloem/Deep_reinforcement_learning_Course/blob/master/Dueling%20Double%20DQN%20with%20PER%20and%20fixed-q%20targets/deadly_corridor.cfg\n",
        "!wget https://github.com/mbloem/Deep_reinforcement_learning_Course/blob/master/Dueling%20Double%20DQN%20with%20PER%20and%20fixed-q%20targets/deadly_corridor.wad"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-23 10:15:16--  https://github.com/mbloem/Deep_reinforcement_learning_Course/blob/master/Dueling%20Double%20DQN%20with%20PER%20and%20fixed-q%20targets/deadly_corridor.cfg\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‚Äòdeadly_corridor.cfg.2‚Äô\n",
            "\n",
            "deadly_corridor.cfg     [ <=>                ]  74.06K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-01-23 10:15:17 (1.45 MB/s) - ‚Äòdeadly_corridor.cfg.2‚Äô saved [75841]\n",
            "\n",
            "--2020-01-23 10:15:17--  https://github.com/mbloem/Deep_reinforcement_learning_Course/blob/master/Dueling%20Double%20DQN%20with%20PER%20and%20fixed-q%20targets/deadly_corridor.wad\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‚Äòdeadly_corridor.wad.1‚Äô\n",
            "\n",
            "deadly_corridor.wad     [ <=>                ]  63.89K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-01-23 10:15:18 (1.25 MB/s) - ‚Äòdeadly_corridor.wad.1‚Äô saved [65422]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QblJyohTzoP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Here we create our environment\n",
        "\"\"\"\n",
        "def create_environment():\n",
        "  game = DoomGame()\n",
        "\n",
        "  game.load_config('deadly_corridor.cfg')\n",
        "\n",
        "  game.set_doom_scenario_path('deadly_corridor.wad')\n",
        "\n",
        "  game.set_window_visible(False)\n",
        "\n",
        "  game.init()\n",
        "\n",
        "  # One-hot version of 7 possible actions\n",
        "  # Or is it 5 actions? turn left, turn right, move left, move right, shoot (attack)\n",
        "  possible_actions = np.identity(7,dtype=int).tolist()\n",
        "\n",
        "  return game, possible_actions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS939CzCzoP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "game, possible_actions = create_environment()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu7_k2GP7IOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "34fc12e0-aa4e-4570-873b-d6048421138c"
      },
      "source": [
        "possible_actions"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0, 0, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ry7W5UuzoQE",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Define the preprocessing functions ‚öôÔ∏è\n",
        "### preprocess_frame\n",
        "Preprocessing is an important step, <b>because we want to reduce the complexity of our states to reduce the computation time needed for training.</b>\n",
        "<br><br>\n",
        "Our steps:\n",
        "- Grayscale each of our frames (because <b> color does not add important information </b>). But this is already done by the config file.\n",
        "- Crop the screen (in our case we remove the roof because it contains no information)\n",
        "- We normalize pixel values\n",
        "- Finally we resize the preprocessed frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjI4SeQdzoQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "preprocess_frame:\n",
        "Take a frame.\n",
        "Resize it.\n",
        "    __________________\n",
        "    |                 |\n",
        "    |                 |\n",
        "    |                 |\n",
        "    |                 |\n",
        "    |_________________|\n",
        "    \n",
        "    to\n",
        "    _____________\n",
        "    |            |\n",
        "    |            |\n",
        "    |            |\n",
        "    |____________|\n",
        "Normalize it.\n",
        "\n",
        "return preprocessed_frame\n",
        "\n",
        "\"\"\"\n",
        "def preprocess_frame(frame):\n",
        "  # Crop screen\n",
        "  cropped_frame = frame[15:-5,20:-20]\n",
        "\n",
        "  # Normalize pixel values\n",
        "  normalized_frame = cropped_frame/255.0\n",
        "\n",
        "  preprocess_frame = transform.resize(cropped_frame, [100,120])\n",
        "\n",
        "  return preprocessed_frame # 100 x 120 x 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDqZdwP3zoQL",
        "colab_type": "text"
      },
      "source": [
        "### stack_frames\n",
        "üëè This part was made possible thanks to help of <a href=\"https://github.com/Miffyli\">Anssi</a><br>\n",
        "\n",
        "As explained in this really <a href=\"https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/\">  good article </a> we stack frames.\n",
        "\n",
        "Stacking frames is really important because it helps us to **give have a sense of motion to our Neural Network.**\n",
        "\n",
        "- First we preprocess frame\n",
        "- Then we append the frame to the deque that automatically **removes the oldest frame**\n",
        "- Finally we **build the stacked state**\n",
        "\n",
        "This is how work stack:\n",
        "- For the first frame, we feed 4 frames\n",
        "- At each timestep, **we add the new frame to deque and then we stack them to form a new stacked frame**\n",
        "- And so on\n",
        "<img src=\"https://raw.githubusercontent.com/simoninithomas/Deep_reinforcement_learning_Course/master/DQN/Space%20Invaders/assets/stack_frames.png\" alt=\"stack\">\n",
        "- If we're done, **we create a new stack with 4 new frames (because we are in a new episode)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXp4-WdXzoQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stack_size = 4 # We stack 4 frames\n",
        "\n",
        "# Initialize deque with zero-images one array for each image\n",
        "stacked_frames  =  deque([np.zeros((100,120), dtype=np.int) for i in range(stack_size)], maxlen=4) \n",
        "\n",
        "def stack_frames(stacked_frames, state, is_new_episode):\n",
        "    # Preprocess frame\n",
        "    frame = preprocess_frame(state)\n",
        "    \n",
        "    if is_new_episode:\n",
        "        # Clear our stacked_frames\n",
        "        stacked_frames = deque([np.zeros((100,120), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
        "        \n",
        "        # Because we're in a new episode, copy the same frame 4x\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        \n",
        "        # Stack the frames\n",
        "        stacked_state = np.stack(stacked_frames, axis=2)\n",
        "\n",
        "    else:\n",
        "        # Append frame to deque, automatically removes the oldest frame\n",
        "        stacked_frames.append(frame)\n",
        "\n",
        "        # Build the stacked state (first dimension specifies different frames)\n",
        "        stacked_state = np.stack(stacked_frames, axis=2) \n",
        "    \n",
        "    return stacked_state, stacked_frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDZTC3PBzoQR",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Set up our hyperparameters ‚öóÔ∏è\n",
        "In this part we'll set up our different hyperparameters. But when you implement a Neural Network by yourself you will **not implement hyperparamaters at once but progressively**.\n",
        "\n",
        "- First, you begin by defining the neural networks hyperparameters when you implement the model.\n",
        "- Then, you'll add the training hyperparameters when you implement the training algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-TQJiYszoQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### MODEL\n",
        "state_size = [100,120,4]  # Input of 4 frames of 100 x 120 x 1\n",
        "action_size = 7 # game.get_available_buttons_size() returns 0 for some reason\n",
        "learning_rate = 0.00025 # alpha (learning rate)\n",
        "\n",
        "### TRAINING\n",
        "total_episodes = 5000\n",
        "max_steps = 5000\n",
        "batch_size = 64\n",
        "\n",
        "# FIXED Q TARGET\n",
        "max_tau = 10000 # this is the C step where we update our target network\n",
        "\n",
        "# EXPLORATION\n",
        "explore_start = 1.0\n",
        "explore_stop = 0.01\n",
        "decay_rate = 0.00005\n",
        "\n",
        "# Q LEARNING\n",
        "gamma = 0.95  # discount rate\n",
        "\n",
        "### MEMORY\n",
        "# If you have GPU then change to 1 million\n",
        "pretrain_length = 10**6   # Number of experiences stored in memory when init time\n",
        "memory_size = 10**6 # Number of experiences memory can keep\n",
        "\n",
        "# Set to false if you only want to see the trained agent\n",
        "training = True\n",
        "\n",
        "# Set to true if you want to render the environment\n",
        "episode_render = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viXGyS296-PG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81a7e717-5950-4218-f6f0-164a8e708156"
      },
      "source": [
        "game.get_available_buttons()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNOaKmtzzoQZ",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Create our Dueling Double Deep Q-learning Neural Network model (aka DDDQN) üß†\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1500/1*FkHqwA2eSGixdS-3dvVoMA.png\" alt=\"Dueling Double Deep Q Learning Model\" />\n",
        "This is our Dueling Double Deep Q-learning model:\n",
        "- We take a stack of 4 frames as input\n",
        "- It passes through 3 convnets\n",
        "- Then it is flatened\n",
        "- Then it is passed through 2 streams\n",
        "    - One that calculates V(s)\n",
        "    - The other that calculates A(s,a)\n",
        "- Finally an agregating layer\n",
        "- It outputs a Q value for each actions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOrQsA-szoQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DDDQNNet:\n",
        "  def __init__(self, state_size, action_size, learning_rate, name):\n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.learning_rate = learning_rate\n",
        "    self.name = name\n",
        "\n",
        "    # Use tf.variable_scope to know which network we're using (DQN or target)\n",
        "    # Will be useful when we update w- params in the target network\n",
        "    # by copying the DQN w params.\n",
        "    with tf.variable_scope(self.name):\n",
        "      self.inputs_ = tf.placeholder(tf.float32, [None, *state_size], name=\"inputs\")\n",
        "      \n",
        "      # Importance sampling weights. \n",
        "      # Why this dimension? Just a float? Might be \"b\" in the IS weight eqn\n",
        "      self.ISWeights_ = tf.placeholder(tf.float32, [None,1], name=\"IS_weights\")\n",
        "\n",
        "      self.actions_ = tf.placeholder(tf.float32, [None, action_size], name=\"actions\")\n",
        "\n",
        "      # target Q(s,a) is R(s,a) + gamma * Q(s', argmax_{a'} Q(s,a',w), w-)\n",
        "      # though for Deuling double DQN we'll decompose into V(s) and A(s,a)\n",
        "      self.target_Q = tf.placeholder(tf.float32,[None], name='target')\n",
        "\n",
        "      \"\"\"\n",
        "      First convnet:\n",
        "      CNN\n",
        "      ELU\n",
        "      \"\"\"\n",
        "      # Input is 100 x 120 x 4\n",
        "      self.conv1 = tf.layers.conv2d(\n",
        "          inputs = self.intputs_,\n",
        "          filters = 32,\n",
        "          kernel_size = [8,8],\n",
        "          strides = [4,4],\n",
        "          padding = 'VALID',\n",
        "          kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d,\n",
        "          name = 'conv1',\n",
        "      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubc1Nu7bzoQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61jbDZKIzoQk",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Prioritized Experience Replay üîÅ\n",
        "Now that we create our Neural Network, **we need to implement the Prioritized Experience Replay method.** <br>\n",
        "\n",
        "As explained in the article, **we can't use a simple array to do that because sampling from it will be not efficient, so we use a binary tree data type (in a binary tree each node has no + than 2 children).** More precisely, a sumtree, which is a binary tree where parents nodes are the sum of the children nodes.\n",
        "\n",
        "If you don't know what is a binary tree check this awesome video https://www.youtube.com/watch?v=oSWTXtMglKE\n",
        "\n",
        "\n",
        "This SumTree implementation was taken from Morvan Zhou in his chinese course about Reinforcement Learning\n",
        "\n",
        "To summarize:\n",
        "- **Step 1**: We construct a SumTree, which is a Binary Sum tree where leaves contains the priorities and a data array where index points to the index of leaves.\n",
        "    <img src=\"https://cdn-images-1.medium.com/max/1200/1*Go9DNr7YY-wMGdIQ7HQduQ.png\" alt=\"SumTree\"/>\n",
        "    <br><br>\n",
        "    - **def __init__**: Initialize our SumTree data object with all nodes = 0 and data (data array) with all = 0.\n",
        "    - **def add**: add our priority score in the sumtree leaf and experience (S, A, R, S', Done) in data.\n",
        "    - **def update**: we update the leaf priority score and propagate through tree.\n",
        "    - **def get_leaf**: retrieve priority score, index and experience associated with a leaf.\n",
        "    - **def total_priority**: get the root node value to calculate the total priority score of our replay buffer.\n",
        "<br><br>\n",
        "- **Step 2**: We create a Memory object that will contain our sumtree and data.\n",
        "    - **def __init__**: generates our sumtree and data by instantiating the SumTree object.\n",
        "    - **def store**: we store a new experience in our tree. Each new experience will **have priority = max_priority** (and then this priority will be corrected during the training (when we'll calculating the TD error hence the priority score).\n",
        "    - **def sample**:\n",
        "         - First, to sample a minibatch of k size, the range [0, priority_total] is / into k ranges.\n",
        "         - Then a value is uniformly sampled from each range\n",
        "         - We search in the sumtree, the experience where priority score correspond to sample values are retrieved from.\n",
        "         - Then, we calculate IS weights for each minibatch element\n",
        "    - **def update_batch**: update the priorities on the tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La0-u50uzoQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9kqf0VbzoQr",
        "colab_type": "text"
      },
      "source": [
        "Here we don't use deque anymore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iXZMN1CzoQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tADnzVEczoQz",
        "colab_type": "text"
      },
      "source": [
        "Here we'll **deal with the empty memory problem**: we pre-populate our memory by taking random actions and storing the experience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkZac8kuzoQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyb9CYWBzoQ5",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: Set up Tensorboard üìä\n",
        "For more information about tensorboard, please watch this <a href=\"https://www.youtube.com/embed/eBbEDRsCmv4\">excellent 30min tutorial</a> <br><br>\n",
        "To launch tensorboard : `tensorboard --logdir=/tensorboard/dddqn/1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN2fY7atzoQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DCNjq8LzoQ_",
        "colab_type": "text"
      },
      "source": [
        "## Step 8: Train our Agent üèÉ‚Äç‚ôÇÔ∏è\n",
        "\n",
        "Our algorithm:\n",
        "<br>\n",
        "* Initialize the weights for DQN\n",
        "* Initialize target value weights w- <- w\n",
        "* Init the environment\n",
        "* Initialize the decay rate (that will use to reduce epsilon) \n",
        "<br><br>\n",
        "* **For** episode to max_episode **do** \n",
        "    * Make new episode\n",
        "    * Set step to 0\n",
        "    * Observe the first state $s_0$\n",
        "    <br><br>\n",
        "    * **While** step < max_steps **do**:\n",
        "        * Increase decay_rate\n",
        "        * With $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s_t,a)$\n",
        "        * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
        "        * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
        "        \n",
        "        * Sample random mini-batch from $D$: $<s, a, r, s'>$\n",
        "        * Set target $\\hat{Q} = r$ if the episode ends at $+1$, otherwise set $\\hat{Q} = r + \\gamma Q(s',argmax_{a'}{Q(s', a', w), w^-)}$\n",
        "        * Make a gradient descent step with loss $(\\hat{Q} - Q(s, a))^2$\n",
        "        * Every C steps, reset: $w^- \\leftarrow w$\n",
        "    * **endfor**\n",
        "    <br><br>\n",
        "* **endfor**\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99iQNoYbzoRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2DDp6_9zoRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYqfQBvVzoRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu73uMMSzoRU",
        "colab_type": "raw"
      },
      "source": [
        "Episode: 0 Total reward: -89.26519775390625 Training loss: 0.6859 Explore P: 0.9919\n",
        "Model Saved\n",
        "Episode: 1 Total reward: -115.13249206542969 Training loss: 1.0044 Explore P: 0.9872\n",
        "Episode: 2 Total reward: -88.6678466796875 Training loss: 30.3196 Explore P: 0.9760\n",
        "Episode: 3 Total reward: -79.75584411621094 Training loss: 0.4285 Explore P: 0.9687\n",
        "Episode: 4 Total reward: -112.888916015625 Training loss: 17.6260 Explore P: 0.9616\n",
        "Episode: 5 Total reward: -72.01809692382812 Training loss: 0.3325 Explore P: 0.9566\n",
        "Model Saved\n",
        "Episode: 6 Total reward: -91.27947998046875 Training loss: 11.2775 Explore P: 0.9489\n",
        "Episode: 7 Total reward: -96.70150756835938 Training loss: 0.8339 Explore P: 0.9412\n",
        "Episode: 8 Total reward: -89.98007202148438 Training loss: 10.4413 Explore P: 0.9368\n",
        "Episode: 9 Total reward: -78.67872619628906 Training loss: 13.1729 Explore P: 0.9292\n",
        "Episode: 10 Total reward: -114.67742919921875 Training loss: 30.3574 Explore P: 0.9192\n",
        "Model Saved\n",
        "Episode: 11 Total reward: -96.40922546386719 Training loss: 1.3338 Explore P: 0.9128\n",
        "Episode: 12 Total reward: -55.94306945800781 Training loss: 1.0281 Explore P: 0.9030\n",
        "Episode: 13 Total reward: -90.61083984375 Training loss: 17.3349 Explore P: 0.8908\n",
        "Episode: 14 Total reward: -110.54817199707031 Training loss: 11.5495 Explore P: 0.8845\n",
        "Episode: 15 Total reward: -86.7437744140625 Training loss: 8.5952 Explore P: 0.8773\n",
        "Model Saved\n",
        "Episode: 16 Total reward: -108.89964294433594 Training loss: 1.6884 Explore P: 0.8730\n",
        "Episode: 17 Total reward: -59.06085205078125 Training loss: 1.4325 Explore P: 0.8659\n",
        "Episode: 18 Total reward: -102.50300598144531 Training loss: 1.0175 Explore P: 0.8593\n",
        "Episode: 19 Total reward: -100.752685546875 Training loss: 7.5007 Explore P: 0.8556\n",
        "Episode: 20 Total reward: -111.81524658203125 Training loss: 5.0652 Explore P: 0.8487\n",
        "Model Saved\n",
        "Episode: 21 Total reward: -104.21478271484375 Training loss: 1.5522 Explore P: 0.8395\n",
        "Episode: 22 Total reward: -112.78564453125 Training loss: 5.5151 Explore P: 0.8359\n",
        "Episode: 23 Total reward: -82.05340576171875 Training loss: 1.2886 Explore P: 0.8292\n",
        "Episode: 24 Total reward: -111.15492248535156 Training loss: 0.5443 Explore P: 0.8225\n",
        "Episode: 25 Total reward: -73.76707458496094 Training loss: 1.5218 Explore P: 0.8156\n",
        "Model Saved\n",
        "Episode: 26 Total reward: -93.35487365722656 Training loss: 0.9257 Explore P: 0.8088\n",
        "Episode: 27 Total reward: -104.47758483886719 Training loss: 2.1761 Explore P: 0.8023\n",
        "Episode: 28 Total reward: -81.60890197753906 Training loss: 0.5991 Explore P: 0.7958\n",
        "Episode: 29 Total reward: -100.63589477539062 Training loss: 1.7395 Explore P: 0.7894\n",
        "Episode: 30 Total reward: -88.62884521484375 Training loss: 8.3556 Explore P: 0.7830\n",
        "Model Saved\n",
        "Episode: 31 Total reward: -105.23612976074219 Training loss: 0.8298 Explore P: 0.7767\n",
        "Episode: 32 Total reward: -111.5128173828125 Training loss: 0.6878 Explore P: 0.7711\n",
        "Episode: 33 Total reward: -107.63644409179688 Training loss: 0.7860 Explore P: 0.7651\n",
        "Episode: 34 Total reward: -99.78999328613281 Training loss: 1.9388 Explore P: 0.7567\n",
        "Episode: 35 Total reward: -107.68731689453125 Training loss: 3.5948 Explore P: 0.7481\n",
        "Model Saved\n",
        "Episode: 36 Total reward: -112.137451171875 Training loss: 0.4563 Explore P: 0.7421\n",
        "Episode: 37 Total reward: -50.57890319824219 Training loss: 0.5308 Explore P: 0.7361\n",
        "Episode: 38 Total reward: -73.00382995605469 Training loss: 1.9759 Explore P: 0.7302\n",
        "Episode: 39 Total reward: -80.82208251953125 Training loss: 0.2969 Explore P: 0.7243\n",
        "Episode: 40 Total reward: -97.41578674316406 Training loss: 16.1484 Explore P: 0.7185\n",
        "Model Saved\n",
        "Episode: 41 Total reward: -77.568115234375 Training loss: 0.2420 Explore P: 0.7128\n",
        "Episode: 42 Total reward: -103.93637084960938 Training loss: 0.1838 Explore P: 0.7026\n",
        "Episode: 43 Total reward: -81.61286926269531 Training loss: 0.3259 Explore P: 0.6948\n",
        "Episode: 44 Total reward: -91.02716064453125 Training loss: 0.3337 Explore P: 0.6859\n",
        "Episode: 45 Total reward: -98.70729064941406 Training loss: 2.1673 Explore P: 0.6804\n",
        "Model Saved\n",
        "Episode: 46 Total reward: -115.98574829101562 Training loss: 14.9863 Explore P: 0.6726\n",
        "Episode: 47 Total reward: -100.81024169921875 Training loss: 2.0342 Explore P: 0.6654\n",
        "Episode: 48 Total reward: -60.25152587890625 Training loss: 0.2753 Explore P: 0.6569\n",
        "Episode: 49 Total reward: -67.41098022460938 Training loss: 0.3018 Explore P: 0.6486\n",
        "Episode: 50 Total reward: -105.46267700195312 Training loss: 1.0995 Explore P: 0.6413\n",
        "Model Saved\n",
        "Episode: 51 Total reward: -73.07460021972656 Training loss: 0.1813 Explore P: 0.6362\n",
        "Episode: 52 Total reward: -96.30844116210938 Training loss: 0.2939 Explore P: 0.6310\n",
        "Episode: 53 Total reward: -94.21073913574219 Training loss: 0.4776 Explore P: 0.6284\n",
        "Episode: 54 Total reward: -65.328125 Training loss: 0.2104 Explore P: 0.6233\n",
        "Episode: 55 Total reward: -66.21479797363281 Training loss: 3.2012 Explore P: 0.6183\n",
        "Model Saved\n",
        "Episode: 56 Total reward: -94.83515930175781 Training loss: 0.5179 Explore P: 0.6136\n",
        "Episode: 57 Total reward: -92.63566589355469 Training loss: 7.6108 Explore P: 0.6068\n",
        "Episode: 58 Total reward: -114.22836303710938 Training loss: 0.1981 Explore P: 0.5979\n",
        "Episode: 59 Total reward: -109.301025390625 Training loss: 0.1633 Explore P: 0.5931\n",
        "Episode: 60 Total reward: -69.18382263183594 Training loss: 0.3027 Explore P: 0.5883\n",
        "Model Saved\n",
        "Episode: 61 Total reward: -96.5882568359375 Training loss: 0.2388 Explore P: 0.5856\n",
        "Episode: 62 Total reward: -115.95585632324219 Training loss: 0.2598 Explore P: 0.5815\n",
        "Episode: 63 Total reward: -91.42893981933594 Training loss: 3.1792 Explore P: 0.5768\n",
        "Episode: 64 Total reward: -78.47196960449219 Training loss: 0.1737 Explore P: 0.5722\n",
        "Episode: 65 Total reward: -33.51860046386719 Training loss: 16.5782 Explore P: 0.5676\n",
        "Model Saved\n",
        "Episode: 66 Total reward: -52.46026611328125 Training loss: 0.7277 Explore P: 0.5630\n",
        "Episode: 67 Total reward: -104.60054016113281 Training loss: 0.1622 Explore P: 0.5585\n",
        "Episode: 68 Total reward: -77.99497985839844 Training loss: 2.5138 Explore P: 0.5540\n",
        "Episode: 69 Total reward: -54.47041320800781 Training loss: 0.1590 Explore P: 0.5496\n",
        "Episode: 70 Total reward: -63.22991943359375 Training loss: 0.1965 Explore P: 0.5452\n",
        "Model Saved\n",
        "Episode: 71 Total reward: -87.78546142578125 Training loss: 0.3122 Explore P: 0.5375\n",
        "Episode: 72 Total reward: -96.14764404296875 Training loss: 0.1515 Explore P: 0.5351\n",
        "Episode: 73 Total reward: -69.32623291015625 Training loss: 2.8430 Explore P: 0.5308\n",
        "Episode: 74 Total reward: -13.840484619140625 Training loss: 0.2721 Explore P: 0.5266\n",
        "Episode: 75 Total reward: -89.6734619140625 Training loss: 0.1506 Explore P: 0.5213\n",
        "Model Saved\n",
        "Episode: 76 Total reward: -64.53419494628906 Training loss: 1.8367 Explore P: 0.5171\n",
        "Episode: 77 Total reward: -106.41300964355469 Training loss: 0.3183 Explore P: 0.5072\n",
        "Episode: 78 Total reward: -50.4837646484375 Training loss: 0.2255 Explore P: 0.5033\n",
        "Episode: 79 Total reward: -34.91241455078125 Training loss: 0.1923 Explore P: 0.4976\n",
        "Episode: 80 Total reward: -115.21119689941406 Training loss: 0.1336 Explore P: 0.4950\n",
        "Model Saved\n",
        "Episode: 81 Total reward: -73.21771240234375 Training loss: 0.1376 Explore P: 0.4911\n",
        "Episode: 82 Total reward: -62.74360656738281 Training loss: 0.6687 Explore P: 0.4871\n",
        "Episode: 83 Total reward: -15.30194091796875 Training loss: 0.1503 Explore P: 0.4778\n",
        "Episode: 84 Total reward: -74.79470825195312 Training loss: 0.1727 Explore P: 0.4740\n",
        "Episode: 85 Total reward: -54.167205810546875 Training loss: 0.1432 Explore P: 0.4702\n",
        "Model Saved\n",
        "Episode: 86 Total reward: -62.83433532714844 Training loss: 0.1632 Explore P: 0.4665\n",
        "Episode: 87 Total reward: -82.97991943359375 Training loss: 0.1923 Explore P: 0.4644\n",
        "Episode: 88 Total reward: -72.07733154296875 Training loss: 0.2274 Explore P: 0.4607\n",
        "Episode: 89 Total reward: -55.19401550292969 Training loss: 0.1261 Explore P: 0.4570\n",
        "Episode: 90 Total reward: -76.98689270019531 Training loss: 0.7601 Explore P: 0.4505\n",
        "Model Saved\n",
        "Episode: 91 Total reward: -65.32528686523438 Training loss: 0.3138 Explore P: 0.4469\n",
        "Episode: 92 Total reward: -50.588714599609375 Training loss: 0.2203 Explore P: 0.4435\n",
        "Episode: 93 Total reward: -70.39730834960938 Training loss: 1.2486 Explore P: 0.4415\n",
        "\n",
        "Episode: 94 Total reward: 70.74258422851562 Training loss: 0.4045 Explore P: 0.4366\n",
        "Episode: 95 Total reward: -11.190460205078125 Training loss: 0.2244 Explore P: 0.4331\n",
        "Model Saved\n",
        "Episode: 96 Total reward: -22.803070068359375 Training loss: 0.4332 Explore P: 0.4297\n",
        "Episode: 97 Total reward: -43.600616455078125 Training loss: 2.4079 Explore P: 0.4265\n",
        "Episode: 98 Total reward: -74.661376953125 Training loss: 0.3113 Explore P: 0.4246\n",
        "Episode: 99 Total reward: -32.23060607910156 Training loss: 0.1899 Explore P: 0.4212\n",
        "Episode: 100 Total reward: -66.32485961914062 Training loss: 0.1400 Explore P: 0.4167\n",
        "Model Saved\n",
        "Episode: 101 Total reward: -15.644882202148438 Training loss: 0.0826 Explore P: 0.4134\n",
        "Episode: 102 Total reward: 44.1182861328125 Training loss: 0.1348 Explore P: 0.4101\n",
        "Episode: 103 Total reward: -61.74578857421875 Training loss: 0.6734 Explore P: 0.4058\n",
        "Episode: 104 Total reward: -87.16415405273438 Training loss: 0.2358 Explore P: 0.4026\n",
        "Episode: 105 Total reward: -90.69143676757812 Training loss: 0.4390 Explore P: 0.3939\n",
        "Model Saved\n",
        "Episode: 106 Total reward: -56.23359680175781 Training loss: 0.1456 Explore P: 0.3908\n",
        "Episode: 107 Total reward: -41.05461120605469 Training loss: 0.9647 Explore P: 0.3877\n",
        "Episode: 108 Total reward: -1.7525482177734375 Training loss: 0.4109 Explore P: 0.3846\n",
        "Episode: 109 Total reward: -37.95100402832031 Training loss: 0.2784 Explore P: 0.3815\n",
        "Episode: 110 Total reward: -71.89024353027344 Training loss: 0.1012 Explore P: 0.3786\n",
        "Model Saved\n",
        "Episode: 111 Total reward: -72.90853881835938 Training loss: 1.4025 Explore P: 0.3756\n",
        "Model updated\n",
        "Episode: 112 Total reward: -56.199127197265625 Training loss: 7.5684 Explore P: 0.3727\n",
        "Episode: 113 Total reward: -77.53300476074219 Training loss: 3.6123 Explore P: 0.3698\n",
        "Episode: 114 Total reward: -50.253692626953125 Training loss: 6.0007 Explore P: 0.3668\n",
        "Episode: 115 Total reward: 18.208023071289062 Training loss: 6.2701 Explore P: 0.3639\n",
        "Model Saved\n",
        "Episode: 116 Total reward: -74.686767578125 Training loss: 7.9382 Explore P: 0.3610\n",
        "Episode: 117 Total reward: -76.70317077636719 Training loss: 3.9754 Explore P: 0.3593\n",
        "Episode: 118 Total reward: 18.843551635742188 Training loss: 1.0298 Explore P: 0.3554\n",
        "Episode: 119 Total reward: 1.3499298095703125 Training loss: 1.5573 Explore P: 0.3525\n",
        "Episode: 120 Total reward: -0.566131591796875 Training loss: 0.4084 Explore P: 0.3497\n",
        "Model Saved\n",
        "Episode: 121 Total reward: 20.053070068359375 Training loss: 0.6762 Explore P: 0.3470\n",
        "Episode: 122 Total reward: -79.74948120117188 Training loss: 0.5085 Explore P: 0.3443\n",
        "Episode: 123 Total reward: -68.07794189453125 Training loss: 0.6844 Explore P: 0.3416\n",
        "Episode: 124 Total reward: 20.166915893554688 Training loss: 0.2775 Explore P: 0.3389\n",
        "Episode: 125 Total reward: -87.4755859375 Training loss: 0.3127 Explore P: 0.3364\n",
        "Model Saved\n",
        "Episode: 126 Total reward: -17.0537109375 Training loss: 0.3796 Explore P: 0.3337\n",
        "Episode: 127 Total reward: 5.201812744140625 Training loss: 0.6150 Explore P: 0.3311\n",
        "Episode: 128 Total reward: -32.572784423828125 Training loss: 0.2595 Explore P: 0.3285\n",
        "Episode: 129 Total reward: -43.18853759765625 Training loss: 0.4992 Explore P: 0.3259\n",
        "Episode: 130 Total reward: -84.01849365234375 Training loss: 0.3338 Explore P: 0.3226\n",
        "Model Saved\n",
        "Episode: 131 Total reward: -99.23286437988281 Training loss: 1.2294 Explore P: 0.3200\n",
        "Episode: 132 Total reward: -27.938064575195312 Training loss: 0.9042 Explore P: 0.3175\n",
        "Episode: 133 Total reward: 2.96868896484375 Training loss: 0.3110 Explore P: 0.3151\n",
        "Episode: 134 Total reward: -49.97503662109375 Training loss: 0.4291 Explore P: 0.3119\n",
        "Episode: 135 Total reward: 8.848037719726562 Training loss: 0.9113 Explore P: 0.3095\n",
        "Model Saved\n",
        "Episode: 136 Total reward: -78.30146789550781 Training loss: 1.1113 Explore P: 0.3064\n",
        "Episode: 137 Total reward: -35.61848449707031 Training loss: 0.2758 Explore P: 0.3039\n",
        "Episode: 138 Total reward: -80.23164367675781 Training loss: 1.1325 Explore P: 0.3015\n",
        "Episode: 139 Total reward: -41.44696044921875 Training loss: 0.2293 Explore P: 0.2993\n",
        "Episode: 140 Total reward: -63.55998229980469 Training loss: 0.5988 Explore P: 0.2969\n",
        "Model Saved\n",
        "Episode: 141 Total reward: -74.58718872070312 Training loss: 0.3622 Explore P: 0.2956\n",
        "Episode: 142 Total reward: -44.1854248046875 Training loss: 0.8818 Explore P: 0.2933\n",
        "Episode: 143 Total reward: -43.17417907714844 Training loss: 0.6441 Explore P: 0.2918\n",
        "Episode: 144 Total reward: -35.05082702636719 Training loss: 0.1932 Explore P: 0.2885\n",
        "Episode: 145 Total reward: 2.6080322265625 Training loss: 0.2974 Explore P: 0.2857\n",
        "Model Saved\n",
        "Episode: 146 Total reward: -75.66334533691406 Training loss: 0.2797 Explore P: 0.2828\n",
        "Episode: 147 Total reward: -79.89767456054688 Training loss: 14.5457 Explore P: 0.2805\n",
        "Episode: 148 Total reward: -65.21456909179688 Training loss: 0.7638 Explore P: 0.2783\n",
        "Episode: 149 Total reward: 13.195510864257812 Training loss: 0.3936 Explore P: 0.2761\n",
        "Episode: 150 Total reward: 60.77146911621094 Training loss: 1.1485 Explore P: 0.2739\n",
        "Model Saved\n",
        "Episode: 151 Total reward: -67.01502990722656 Training loss: 1.1541 Explore P: 0.2710\n",
        "Episode: 152 Total reward: 7.119903564453125 Training loss: 0.4257 Explore P: 0.2689\n",
        "Episode: 153 Total reward: 13.754486083984375 Training loss: 0.4931 Explore P: 0.2639\n",
        "Episode: 154 Total reward: -67.7314453125 Training loss: 0.5301 Explore P: 0.2618\n",
        "Episode: 155 Total reward: -61.25654602050781 Training loss: 0.3877 Explore P: 0.2599\n",
        "Model Saved\n",
        "Episode: 156 Total reward: -1.2131805419921875 Training loss: 0.3397 Explore P: 0.2579\n",
        "Episode: 157 Total reward: -26.2254638671875 Training loss: 0.1870 Explore P: 0.2558\n",
        "Episode: 158 Total reward: 71.63455200195312 Training loss: 0.3283 Explore P: 0.2538\n",
        "Episode: 159 Total reward: -41.72747802734375 Training loss: 0.6035 Explore P: 0.2520\n",
        "Episode: 160 Total reward: -75.83839416503906 Training loss: 0.5253 Explore P: 0.2488\n",
        "Model Saved\n",
        "Episode: 161 Total reward: 3.0420074462890625 Training loss: 0.8875 Explore P: 0.2468\n",
        "Episode: 162 Total reward: -21.011383056640625 Training loss: 0.2739 Explore P: 0.2449\n",
        "Episode: 163 Total reward: -19.587127685546875 Training loss: 1.2479 Explore P: 0.2431\n",
        "Episode: 164 Total reward: -53.40458679199219 Training loss: 1.2350 Explore P: 0.2413\n",
        "Episode: 165 Total reward: -59.686767578125 Training loss: 0.4527 Explore P: 0.2395\n",
        "Model Saved\n",
        "Episode: 166 Total reward: -53.43865966796875 Training loss: 12.8202 Explore P: 0.2384\n",
        "Episode: 167 Total reward: 4.73968505859375 Training loss: 0.2532 Explore P: 0.2366\n",
        "Episode: 168 Total reward: -42.3804931640625 Training loss: 0.6826 Explore P: 0.2347\n",
        "Episode: 169 Total reward: -1.4572296142578125 Training loss: 0.5197 Explore P: 0.2329\n",
        "Episode: 170 Total reward: -39.27558898925781 Training loss: 11.5407 Explore P: 0.2311\n",
        "Model Saved\n",
        "Episode: 171 Total reward: 8.362579345703125 Training loss: 0.2713 Explore P: 0.2295\n",
        "Episode: 172 Total reward: 14.519943237304688 Training loss: 7.7963 Explore P: 0.2277\n",
        "Episode: 173 Total reward: -58.884429931640625 Training loss: 0.3072 Explore P: 0.2259\n",
        "Episode: 174 Total reward: -93.07179260253906 Training loss: 0.6735 Explore P: 0.2235\n",
        "Episode: 175 Total reward: -60.440277099609375 Training loss: 0.6426 Explore P: 0.2218\n",
        "Model Saved\n",
        "Episode: 176 Total reward: 24.163375854492188 Training loss: 0.5932 Explore P: 0.2201\n",
        "Episode: 177 Total reward: -74.15121459960938 Training loss: 0.1940 Explore P: 0.2191\n",
        "Episode: 178 Total reward: -47.54103088378906 Training loss: 0.9826 Explore P: 0.2174\n",
        "Episode: 179 Total reward: -88.96371459960938 Training loss: 0.6407 Explore P: 0.2157\n",
        "Episode: 180 Total reward: 86.02571105957031 Training loss: 0.3157 Explore P: 0.2134\n",
        "Model Saved\n",
        "Episode: 181 Total reward: -8.269500732421875 Training loss: 1.0492 Explore P: 0.2118\n",
        "Episode: 182 Total reward: 37.916839599609375 Training loss: 0.3531 Explore P: 0.2102\n",
        "Episode: 183 Total reward: 28.824462890625 Training loss: 0.3685 Explore P: 0.2086\n",
        "Episode: 184 Total reward: -103.504150390625 Training loss: 0.8678 Explore P: 0.2077\n",
        "Episode: 185 Total reward: -33.638336181640625 Training loss: 0.5436 Explore P: 0.2062\n",
        "Model Saved\n",
        "Episode: 186 Total reward: -46.80809020996094 Training loss: 0.8421 Explore P: 0.2046\n",
        "\n",
        "Episode: 187 Total reward: 4.5064849853515625 Training loss: 0.2865 Explore P: 0.2030\n",
        "Episode: 188 Total reward: -10.029891967773438 Training loss: 0.4644 Explore P: 0.2014\n",
        "Episode: 189 Total reward: -35.31138610839844 Training loss: 0.3323 Explore P: 0.1999\n",
        "Episode: 190 Total reward: 22.30352783203125 Training loss: 0.6971 Explore P: 0.1984\n",
        "Model Saved\n",
        "Episode: 191 Total reward: -54.252655029296875 Training loss: 0.7283 Explore P: 0.1968\n",
        "Episode: 192 Total reward: -94.67848205566406 Training loss: 1.4658 Explore P: 0.1959\n",
        "Episode: 193 Total reward: -38.33479309082031 Training loss: 0.2945 Explore P: 0.1944\n",
        "Episode: 194 Total reward: -96.05851745605469 Training loss: 0.2530 Explore P: 0.1929\n",
        "Episode: 195 Total reward: -16.951339721679688 Training loss: 0.8220 Explore P: 0.1914\n",
        "Model Saved\n",
        "Episode: 196 Total reward: -104.72447204589844 Training loss: 0.4501 Explore P: 0.1900\n",
        "Episode: 197 Total reward: -3.453094482421875 Training loss: 0.4974 Explore P: 0.1886\n",
        "Episode: 198 Total reward: -26.187362670898438 Training loss: 0.2195 Explore P: 0.1872\n",
        "Episode: 199 Total reward: -98.55648803710938 Training loss: 0.2501 Explore P: 0.1864\n",
        "Episode: 200 Total reward: -16.166595458984375 Training loss: 0.3163 Explore P: 0.1850\n",
        "Model Saved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAhPzuV0zoRb",
        "colab_type": "text"
      },
      "source": [
        "## Step 9: Watch our Agent play üëÄ\n",
        "Now that we trained our agent, we can test it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xmGQICzzoRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}